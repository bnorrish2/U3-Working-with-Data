{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [CPSC 222](https://github.com/GonzagaCPSC222) Intro to Data Science\n",
    "[Gonzaga University](https://www.gonzaga.edu/)\n",
    "\n",
    "[Gina Sprint](http://cs.gonzaga.edu/faculty/sprint/)\n",
    "\n",
    "# Data Processing\n",
    "What are our learning objectives for this lesson?\n",
    "* Clean data by filling missing values\n",
    "* Perform data aggregation w/split-apply-combine\n",
    "\n",
    "Content used in this lesson is based upon information in the following sources:\n",
    "* Dr. Shawn Bowers' Data Mining notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing\n",
    "Data analysts spend a surprising amount of time preparing data for analysis. In fact, a survey was conducted found that cleaning big data is the most time-consuming and least enjoyable task data scientists do!\n",
    "<img src=\"https://thumbor.forbes.com/thumbor/960x0/https%3A%2F%2Fblogs-images.forbes.com%2Fgilpress%2Ffiles%2F2016%2F03%2FTime-1200x511.jpg\" width=\"700\">\n",
    "(image from [https://thumbor.forbes.com/thumbor/960x0/https%3A%2F%2Fblogs-images.forbes.com%2Fgilpress%2Ffiles%2F2016%2F03%2FTime-1200x511.jpg](https://thumbor.forbes.com/thumbor/960x0/https%3A%2F%2Fblogs-images.forbes.com%2Fgilpress%2Ffiles%2F2016%2F03%2FTime-1200x511.jpg))\n",
    "\n",
    "The goal of data preprocessing is to produce high-quality data to improve mining results and efficiency\n",
    "\n",
    "At a high level, data preprocessing includes the following steps (these steps are done in any order and often multiple times):\n",
    "1. Data Exploration (basic understanding of meaning, attributes, values, issues)\n",
    "2. Data Reduction (reduce size via aggregation, redundant features, etc.)\n",
    "3. Data Integration (join/merge/combine multiple datasets)\n",
    "4. Data Cleaning (remove noise and inconsistencies)\n",
    "    * Dealing with missing values\n",
    "    * Dealing with incorrect values (e.g., misspelled names, values out of range)\n",
    "5. Data Transformation (normalize/scale, to discrete values, etc.)\n",
    "\n",
    "It is important for data mining that your process is transparent and repeatable:\n",
    "* Can repeat \"experiment\" and get the same result\n",
    "* No \"magic\" steps\n",
    "\n",
    "It is important, however, to write down steps (log):\n",
    "* Ideally, someone should be able to take your data, program, and description of steps, rerun everything, and get the same results!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "It is not uncommon to have datasets with noisy, invalid, or completely missing values.\n",
    "1. Noisy vs Invalid Values\n",
    "    * Noisy implies the value is correct, just recorded incorrectly\n",
    "        * E.g., decimal place error (5.72 instead of 57.2), wrong categorical value used\n",
    "    * Invalid implies a noisy value that is not a valid value (for domain)\n",
    "        * E.g., 57.2X, misspelled categorical data, or value out of range (6 on a 5 point scale)\n",
    "    * Ways to deal with this:\n",
    "        * Look for duplicates (when there shouldn't be)\n",
    "        * Look for outliers\n",
    "        * Sort and print range of values\n",
    "    * The term \"noisy\" may also imply random error or random variance\n",
    "        * Various techniques to \"smooth out\" values\n",
    "        * E.g., using means of bins or regression\n",
    "2. Missing Values\n",
    "     * How should we deal with missing values?\n",
    "        * Discard instances: throw out any row with a missing value\n",
    "        * Replace with a new value:\n",
    "            * By hand\n",
    "            * Use a constant\n",
    "            * Use a central tendency measure (mean, median, most frequent, ...)\n",
    "        * Most \"probable\" value (e.g., regression, using a classifier)\n",
    "        * Replace either across data set, or based on similar instances\n",
    "            * E.g. average based on model year\n",
    "            \n",
    "Missing values are usually coded as an out of range value, such as an empty string in a text field, -1 in a numeric field that is normally positive, or 0 in a numeric field that cannot take on the value of 0. In the Scipy ecosystem, the common value `NaN` (not a number) is used to denote missing data. There is support in the Scipy libraries to handle `NaN` specially. For example, the Pandas function [`isnull()`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.isnull.html) returns a Boolean array detecting the `NaN` values element-wise and [`dropna()`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.dropna.html) removes `NaN` values from a series or data frame:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Cleaning Example\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "x = np.arange(0, 10)\n",
    "ser = pd.Series(x)\n",
    "ser[1] = np.NaN\n",
    "ser[5] = np.NaN\n",
    "nans = ser.isnull()\n",
    "# count the number of missing values\n",
    "print(nans.sum())\n",
    "print(ser)\n",
    "ser.dropna(inplace=True)\n",
    "print(ser)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: you can learn more about missing data by reading [Pandas website](https://pandas.pydata.org/pandas-docs/stable/missing_data.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By learning how to use the Pandas library, we have the skills to perform many of the tasks listed above. In this lesson, we are going to focus on *data cleaning*, modifying the data to make it sufficiently accurate and structured to support the analysis you want to perform. To learn about data cleaning, we are going to clean data by working through an example!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Aggregation\n",
    "Gathering and summarizing information, perhaps in preparation for statistical analysis or visualization, is called *data aggregation*. For example, suppose you want to investigate the similarities/differences amongst patients in a clinical setting. Suppose specific attributes you are interested in include medical condition, age, and gender. You might *group* the data into two groups: male and female. By grouping the data based on a variable, such as gender, you are aggregating the data. The grouping allows you to then create a bar chart representing the frequency of each medical condition present in each group, or perform hypothesis testing to see if there is a significant age difference between the two groups. \n",
    "\n",
    "### Split-Apply-Combine\n",
    "Data aggregation typically follows a \"split, apply, combine\" process:\n",
    "* Split the data into groups based on some criteria\n",
    "    * Perform *group by* operations\n",
    "    * Select or slice data to form a subset\n",
    "    * Example: Group a data frame by rows (axis 0) or by columns (axis 1)\n",
    "* Apply a function to each group independently, producing a new value\n",
    "    * Compute summary statistics (aggregation)\n",
    "        * Example: Count the size of each group\n",
    "        * Example: Compute mean, standard deviation, custom stats, etc.\n",
    "    * Transform the data in the group (transformation)\n",
    "        * Example: Standardizing data (z-score) within each group\n",
    "        * Example: Filling missing data with a value derived from each group\n",
    "    * Discard some groups (filtration)\n",
    "        * Example: Discarding data that belongs to groups with only a few members\n",
    "        * Example: Filtering out data based on the group sum or mean\n",
    "* Combine the results of the function applications into a data structure\n",
    "    * Example: A series with index corresponding to data frame column names and values representing the column means\n",
    "    \n",
    "<img src=\"http://blog.yhat.com/static/img/split-apply-combine.jpg\" width=\"500\">\n",
    "(image from [http://blog.yhat.com/static/img/split-apply-combine.jpg](http://blog.yhat.com/static/img/split-apply-combine.jpg))\n",
    "    \n",
    "### Pandas GroupBy\n",
    "In the split step, we want to divide a dataset into a mapping of group names to group data. With the Pandas [`groupby()`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.groupby.html) function, we can divide a data frame into a [`GroupBy`](http://pandas.pydata.org/pandas-docs/stable/groupby.html) object that stores the mapping. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  AgeGroup  Feature1  Feature2 Gender\n",
      "0       OA  0.526954  0.352297      F\n",
      "1        A  0.419304 -0.145591      F\n",
      "2       OA -1.541056 -0.701479      M\n",
      "3       YA -1.003222  0.511651      F\n",
      "4       YA  0.906797  0.559671      M\n",
      "5       OA -0.541548 -0.428555      M\n",
      "6        A  1.321634 -1.693548      M\n",
      "7       YA -0.475034 -1.297328      F\n",
      "Groups: {'F': [0, 1, 3, 7], 'M': [2, 4, 5, 6]}\n",
      "Female data frame\n",
      "  AgeGroup  Feature1  Feature2 Gender\n",
      "0       OA  0.526954  0.352297      F\n",
      "1        A  0.419304 -0.145591      F\n",
      "3       YA -1.003222  0.511651      F\n",
      "7       YA -0.475034 -1.297328      F\n",
      "Male data frame\n",
      "  AgeGroup  Feature1  Feature2 Gender\n",
      "2       OA -1.541056 -0.701479      M\n",
      "4       YA  0.906797  0.559671      M\n",
      "5       OA -0.541548 -0.428555      M\n",
      "6        A  1.321634 -1.693548      M\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# adapted from http://pandas.pydata.org/pandas-docs/stable/groupby.html\n",
    "df = pd.DataFrame({\"Gender\" : [\"F\", \"F\", \"M\", \"F\", \"M\", \"M\", \"M\", \"F\"],\n",
    "                   \"AgeGroup\" : [\"OA\", \"A\", \"OA\", \"YA\", \"YA\", \"OA\", \"A\", \"YA\"], # OA: older adult, A: adult, YA: young adult\n",
    "                   \"Feature1\" : np.random.randn(8),\n",
    "                   \"Feature2\" : np.random.randn(8)})\n",
    "print(df)\n",
    "# GroupBy object (mapping of group name -> group data frame)\n",
    "gender_groups = df.groupby(\"Gender\")\n",
    "# groups attribute is a dictionary storing the mapping\n",
    "print(\"Groups:\", gender_groups.groups)\n",
    "print(\"Female data frame\")\n",
    "F_df = gender_groups.get_group(\"F\")\n",
    "print(F_df)\n",
    "print(\"Male data frame\")\n",
    "M_df = gender_groups.get_group(\"M\")\n",
    "print(M_df)\n",
    "# confirm M_df is a data frame\n",
    "print(type(M_df))\n",
    "# divided the data frame into 2 groups\n",
    "print(len(df) == len(F_df) + len(M_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have learned enough background information to dive into learning about aggregating data by working through an example!\n",
    "\n",
    "## Data Aggregation Example\n",
    "We are going to an example with the following dataset pd_hoa_activities.csv. This dataset contains information from a smart home study where participants performed 9 activities in a smart home environment. pd_hoa_activities_cleaned.csv is a version of the data that is already cleaned. We will start with this cleaned version of the dataset. You can download this file at: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(665, 3)\n",
      "                               duration  age class\n",
      "pid task                                          \n",
      "0   Water Plants                    146   72   HOA\n",
      "    Fill Medication Dispenser       210   72   HOA\n",
      "    Wash Countertop                 241   72   HOA\n",
      "    Sweep and Dust                  328   72   HOA\n",
      "    Cook                            229   72   HOA\n",
      "    Wash Hands                       38   72   HOA\n",
      "    Perform TUG                      10   72   HOA\n",
      "    Perform TUG w/Questions          10   72   HOA\n",
      "    Day Out Task                    680   72   HOA\n",
      "1   Water Plants                     63   54   HOA\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "fname = r\"files\\pd_hoa_activities_cleaned.csv\"\n",
    "df = pd.read_csv(fname, header=0, index_col=[0, 1])\n",
    "print(df.shape)\n",
    "print(df.head(n=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split\n",
    "Now let's group the data into two population groups, HOA and PD. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HOA\n",
      "                               duration  age class\n",
      "pid task                                          \n",
      "0   Water Plants                    146   72   HOA\n",
      "    Fill Medication Dispenser       210   72   HOA\n",
      "    Wash Countertop                 241   72   HOA\n",
      "    Sweep and Dust                  328   72   HOA\n",
      "    Cook                            229   72   HOA\n",
      "PD\n",
      "                               duration  age class\n",
      "pid task                                          \n",
      "2   Water Plants                     47   62    PD\n",
      "    Fill Medication Dispenser       205   62    PD\n",
      "    Wash Countertop                 232   62    PD\n",
      "    Sweep and Dust                  543   62    PD\n",
      "    Cook                            511   62    PD\n"
     ]
    }
   ],
   "source": [
    "classes = df.groupby(\"class\")\n",
    "for class_name, cls_df in classes:\n",
    "    print(class_name)\n",
    "    print(cls_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply and Combine\n",
    "Then, we can compute summary statistics for each group, such as mean and standard deviation for age. we will store the results in a new results data frame with index \"HOA\" and \"PD:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    age mean  age std\n",
      "HOA  68.6771  9.78872\n",
      "PD   68.8539  9.88264\n"
     ]
    }
   ],
   "source": [
    "age_results_df = pd.DataFrame(index=classes.groups, columns=[\"age mean\", \"age std\"])\n",
    "for class_name, cls_df in classes:\n",
    "    age_results_df.ix[class_name][\"age mean\"] = cls_df[\"age\"].mean()\n",
    "    age_results_df.ix[class_name][\"age std\"] = cls_df[\"age\"].std()\n",
    "print(age_results_df)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
